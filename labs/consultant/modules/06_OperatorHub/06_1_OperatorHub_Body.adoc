include::../../tools/00_0_Lab_Header.adoc[]
:imagesdir: ./images

== {labname} Lab

.Goals

* Learn how to install operators from OperatorHub using the web console
* Explore the Operator Lifecycle Manager (OLM) infrastructure
* Learn how to install operators from OperatorHub using CLI
* Learn how to disable and enable operator sources

In this lab you will install an Operator from OperatorHub, study its structure and
components, then uninstall it and install it again using just command line.

[[labexercises]]
:numbered:

== Install Operator using Web Console

In this exercises you install an operator using the web console.
It's the easiest way because OpenShift performs some operations for you behind the scenes.
But we can watch how OpenShift does that so we can reproduce and automate this operation in the future.

. Log in your web console with user: karla or david. Then go to *Operators* -> *OperatorHub*. 

. In the "Filter by keyword" search field enter *nfd*.
+
image::operatorhub-nfd.png[]

. Click on the "Node Feature Discovery" item and read its description.

. Click the "Install" button.

. On the next screen you have to create a Subscription. 
+
Here you can specify:
+
* Whether to install the Operator on all namespaces or only one. 
In this case you should take the default and install the Operator on all namespaces.
You will see later that the NodeFeatureDiscovery instances will be copied into all namespaces
to allow cluster users to use hardware-specific labels.
* Which update channel to use. In our case we use "*4.5*" which is our current cluster version. Always make sure to install the channel that matches your OpenShift cluster.
* Approval Strategy: Automatic or Manual. Choose the default -- "*Automatic*"

. Click "*Subscribe*"

. After several seconds you will see the "*InstallSucceeded*" status in the list of
Installed Operators. If you do not see this, switch your project to the `openshift-operators` project.

. Now the Operator is running, the Subscription is active but we haven't created any
resources yet. Click on the "Node Feature Discovery" link in the first column.
It will take you to this page:
+
image::nfd-create-instance.png[]
+
From this page you can install a Node Feature Discovery instance. But before installing it,
gather some information about the operator itself.

. Click on the *YAML* tab. You will see the ClusterServiceVersion manifest.
+
From this manifest you can figure out:
+
* The source code repository URL where you can find more information about this operator
* The Operator's provider, capabilities, description, etc.
* Important: Example of a Custom Resource that is managed by this Operator. Look for a JSON 
file under `alm-examples`. You will see that NFD instances are installed in the `openshift-nfd`
namespace. 
+
Learn more about the fields that are required in every CSV: https://github.com/operator-framework/community-operators/blob/master/docs/required-fields.md

. Switch to the *Subscription* tab. Here you find out that one subscription for this
operator is installed in the cluster; its channel and approval policy. 
The subcription is installed in the `openshift-operators` namespace: this is the 
default for cluster-wide operators.

. On the Subscription page click on the *Install Plan* on the right side of the page.
+
Click on the *Components* tab.

. Explore the cluster resources that were installed when you deployed this Operator.
+
You will find the following resources:
+
* ClusterServiceVersion
* CustomResourceDefinition (for `NodeFeatureDiscovery`)
* ServiceAccount `nfd-operator`
* ClusterRole
* ClusterRoleBinding

. You will need to create a new namespace for the *Node Feature Discovery* pods to run in.
. On the left navigate to *Administration* > *Namespaces*
. Click *Create Namespace* and use `openshift-nfd` as the Name. Leave all other settings as they are and click on  *Create*.
. Navigate back to *Installed Operators*.
. From the *Project* dropdown at the top select the newly created `openshift-nfd` project if it's not already selected.
. Navigate back to *Installed Operators* > *Node Feature Discovery*. Click on the *Node Feature Discovery* tab.
+
image::nfd-no-operands.png[]
+
Here you will find a page which tells you that you don't have any NodeFeatureDiscovery operands installed in the cluster.
Click on the *Create Node Feature Discovery* button.

. On the next screen switch to the *YAML View* radio button and you will see a YAML manifest describing the NodeFeatureDiscovery instance you are about to create. 
+
In this manifest you see two namespaces.
In the `openshift-nfd` namespace you create a `NodeFeatureDiscovery` resource which is called `nfd-master-server`. 
Also in the `openshift-nfd` namespace the Operator will create the Pods, DaemonSets, and Service that comprise the `nfd-operator`.
+
Click *Create*.
You will be transferred to the next page that shows the `NodeFeatureDiscovery` resource you've just created:
+
image::nfd-1-instance.png[]

. Click on the `nfd-master-server` link and then on the *YAML* tab. 
You will see the description of this `NodeFeatureDiscovery` resource.
+
[source,sh]
----
apiVersion: nfd.openshift.io/v1alpha1
kind: NodeFeatureDiscovery
metadata:
  creationTimestamp: '2020-08-10T21:24:50Z'
  generation: 1
  managedFields:
    - apiVersion: nfd.openshift.io/v1alpha1
      fieldsType: FieldsV1
      fieldsV1:
        'f:spec': {}
      manager: Mozilla
      operation: Update
      time: '2020-08-10T21:24:50Z'
  name: nfd-master-server
  namespace: openshift-nfd
  resourceVersion: '129381'
  selfLink: >-
    /apis/nfd.openshift.io/v1alpha1/namespaces/openshift-nfd/nodefeaturediscoveries/nfd-master-server
  uid: 45ed3296-1a85-4921-8881-1cd1266c27b9
spec: {}
----

. Click on the *Operators* -> *Installed Operators* in the left-side menu.
Choose *all projects* from the *Project* drop-down menu.
+
You see that the `nfd-operator` was copied into all namespaces. This is part of its configuration
and it's done to make the information collected by this operator available in all projects.

Now, after you have installed the operator and its resources, explore them from the terminal session.
This will prepare you for command line installation.

== Explore the Operator from Command Line

. Open an SSH session to your `bastion`.

. Check what was deployed in the `openshift-operators` namespace:
+
[source,options="nowrap",subs="{markup-in-source}"]
----
$ *oc get all -n openshift-operators*
NAME                               READY   STATUS    RESTARTS   AGE
pod/nfd-operator-7b5dcf546-l6pds   1/1     Running   0          9m52s

NAME                           READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/nfd-operator   1/1     1            1           9m52s

NAME                                     DESIRED   CURRENT   READY   AGE
replicaset.apps/nfd-operator-7b5dcf546   1         1         1       9m52s
----

. Check the events in the `openshift-operators` namespace:
+
[source,options="nowrap"]
----
$ oc get events -n openshift-operators
LAST SEEN   TYPE     REASON                OBJECT                                            MESSAGE
<unknown>   Normal   Scheduled             pod/nfd-operator-7b5dcf546-l6pds                  Successfully assigned openshift-operators/nfd-operator-7b5dcf546-l6pds to cluster-7a2f-bl5bg-master-2
10m         Normal   AddedInterface        pod/nfd-operator-7b5dcf546-l6pds                  Add eth0 [10.130.0.10/23]
10m         Normal   Pulling               pod/nfd-operator-7b5dcf546-l6pds                  Pulling image "registry.redhat.io/openshift4/ose-cluster-nfd-operator@sha256:e8f8d41a3ff8e420e648d27bb1f8f6fcdac9dd17d6cbc117855b2a84f0726c2c"
10m         Normal   Pulled                pod/nfd-operator-7b5dcf546-l6pds                  Successfully pulled image "registry.redhat.io/openshift4/ose-cluster-nfd-operator@sha256:e8f8d41a3ff8e420e648d27bb1f8f6fcdac9dd17d6cbc117855b2a84f0726c2c"
10m         Normal   Created               pod/nfd-operator-7b5dcf546-l6pds                  Created container nfd-operator
10m         Normal   Started               pod/nfd-operator-7b5dcf546-l6pds                  Started container nfd-operator
10m         Normal   SuccessfulCreate      replicaset/nfd-operator-7b5dcf546                 Created pod: nfd-operator-7b5dcf546-l6pds
10m         Normal   ScalingReplicaSet     deployment/nfd-operator                           Scaled up replica set nfd-operator-7b5dcf546 to 1
10m         Normal   RequirementsUnknown   clusterserviceversion/nfd.4.5.0-202007281827.p0   requirements not yet checked
10m         Normal   RequirementsNotMet    clusterserviceversion/nfd.4.5.0-202007281827.p0   one or more requirements couldn't be found
10m         Normal   AllRequirementsMet    clusterserviceversion/nfd.4.5.0-202007281827.p0   all requirements found, attempting install
10m         Normal   InstallSucceeded      clusterserviceversion/nfd.4.5.0-202007281827.p0   waiting for install components to report healthy
10m         Normal   InstallWaiting        clusterserviceversion/nfd.4.5.0-202007281827.p0   installing: waiting for deployment nfd-operator to become ready: Waiting for deployment spec update to be observed...
10m         Normal   InstallWaiting        clusterserviceversion/nfd.4.5.0-202007281827.p0   installing: waiting for deployment nfd-operator to become ready: Waiting for rollout to finish: 0 out of 1 new replicas have been updated...
10m         Normal   InstallWaiting        clusterserviceversion/nfd.4.5.0-202007281827.p0   installing: waiting for deployment nfd-operator to become ready: Waiting for rollout to finish: 0 of 1 updated replicas are available...
9m50s       Normal   InstallSucceeded      clusterserviceversion/nfd.4.5.0-202007281827.p0   install strategy completed with no errors
----

. Analyze the list of events. You can easily see what has happened:
+
* The Deployment `nfd-operator` was created
** Remember, that each operator is a Pod or set of Pods and those Pods are usually a part
of a Deployment
* The ClusterServiceVersion looked for and found all the requireemnts
* A Pod with the `nfd-operator` was created and started
** It uses a container image which is specified in its ClusterServiceVersion

. Now check what was created in the `openshift-nfd` namespace.
+
[source,options="nowrap",subs="{markup-in-source}"]
----
$ *oc get all -n openshift-nfd*
NAME                   READY   STATUS    RESTARTS   AGE
pod/nfd-master-8vrbq   1/1     Running   0          3m19s
pod/nfd-master-ddr76   1/1     Running   0          3m19s
pod/nfd-master-gct4p   1/1     Running   0          3m19s
pod/nfd-worker-bmqdd   1/1     Running   1          3m20s
pod/nfd-worker-pn95t   1/1     Running   1          3m20s
pod/nfd-worker-sh625   1/1     Running   1          3m20s

NAME                 TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)     AGE
service/nfd-master   ClusterIP   172.30.209.169   <none>        12000/TCP   3m20s

NAME                        DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR                     AGE
daemonset.apps/nfd-master   3         3         3       3            3           node-role.kubernetes.io/master=   3m20s
daemonset.apps/nfd-worker   3         3         3       3            3           node-role.kubernetes.io/worker=   3m20s
----
+
You notice that the operator has created two DaemonSets and started six Pods.
Those Pods will be reporting the Node's hardware and software features like GPU, SSD, OC version, etc.
Using this information you will be able to schedule certain applications to nodes
with special hardware. We are not covering it in this module, but you can check it yourself
by going to the GUI and checking nodes' labels.

. Check the Subscription created by the Operator:
+
[source,options="nowrap",subs="{markup-in-source}"]
----
$ *oc get subscription -n openshift-operators*
NAME   PACKAGE   SOURCE             CHANNEL
nfd    nfd       redhat-operators   4.5

$ *oc get subscription nfd -o yaml -n openshift-operators*

apiVersion: operators.coreos.com/v1alpha1
kind: Subscription
metadata:
  creationTimestamp: "2020-08-10T21:17:31Z"
  generation: 1
  managedFields:

[...]

  name: nfd
  namespace: openshift-operators
  resourceVersion: "126538"
  selfLink: /apis/operators.coreos.com/v1alpha1/namespaces/openshift-operators/subscriptions/nfd
  uid: c8cddd09-abda-4654-8922-403a9c480a4b
spec:
  channel: "4.5"
  installPlanApproval: Automatic
  name: nfd
  source: redhat-operators
  sourceNamespace: openshift-marketplace
  startingCSV: nfd.4.5.0-202007281827.p0
status:
  catalogHealth:
  - catalogSourceRef:
      apiVersion: operators.coreos.com/v1alpha1
      kind: CatalogSource
      name: certified-operators
      namespace: openshift-marketplace
      resourceVersion: "105470"
      uid: 4e0e82cb-b113-4478-ae09-a1a5909a9cee
    healthy: true
    lastUpdated: "2020-08-10T21:17:32Z"
  - catalogSourceRef:
      apiVersion: operators.coreos.com/v1alpha1
      kind: CatalogSource
      name: community-operators
      namespace: openshift-marketplace
      resourceVersion: "105467"
      uid: 71bdb5cd-9f29-4eb9-b469-38f1b9365dd9
    healthy: true
    lastUpdated: "2020-08-10T21:17:32Z"
  - catalogSourceRef:
      apiVersion: operators.coreos.com/v1alpha1
      kind: CatalogSource
      name: redhat-marketplace
      namespace: openshift-marketplace
      resourceVersion: "105466"
      uid: 1a63b80b-b6ce-407d-b180-74f521f8e65e
    healthy: true
    lastUpdated: "2020-08-10T21:17:32Z"
  - catalogSourceRef:
      apiVersion: operators.coreos.com/v1alpha1
      kind: CatalogSource
      name: redhat-operators
      namespace: openshift-marketplace
      resourceVersion: "105468"
      uid: 2c22df82-40d1-46ff-b23e-6eeaf528f622
    healthy: true
    lastUpdated: "2020-08-10T21:17:32Z"
  conditions:
  - lastTransitionTime: "2020-08-10T21:17:32Z"
    message: all available catalogsources are healthy
    reason: AllCatalogSourcesHealthy
    status: "False"
    type: CatalogSourcesUnhealthy
  currentCSV: nfd.4.5.0-202007281827.p0
  installPlanGeneration: 1
  installPlanRef:
    apiVersion: operators.coreos.com/v1alpha1
    kind: InstallPlan
    name: install-lllv8
    namespace: openshift-operators
    resourceVersion: "126383"
    uid: eadb5fc1-c0a4-4fdc-8b19-344f0514f3a0
  installedCSV: nfd.4.5.0-202007281827.p0
  installplan:
    apiVersion: operators.coreos.com/v1alpha1
    kind: InstallPlan
    name: install-lllv8
    uuid: eadb5fc1-c0a4-4fdc-8b19-344f0514f3a0
  lastUpdated: "2020-08-10T21:17:37Z"
  state: UpgradeAvailable
----

To summarize the Operator installation process:

* Install an Operator
* Create a Subscription
* Create resources managed by this Operator

== Delete Operator using Web Console

We have installed the NFD Operator "the easy way". In the next exercise we will repeat 
this operation, but using command line. Before starting that exercise, delete everything 
you have created via GUI.

. Start with deleting the NodeFeatureDiscovery resource.
Switch back to the `openshift-nfd` project and go to the *Installed Operators* -> *Node Feature Discovery* link -> *Node Feature Discovery* tab.
+
On the right side find the "three-dots" menu and find the "Delete Node Feature Discovery" item.

. Delete the Operator with its Subscription. Switch to the `openshift-operators project and go to *Installed Operators* and on the right side open the "three-dots" menu and choose *Uninstall Operator*

. Make sure that you have nothing in *Installed Operators* in the `openshift-operators` namespace.

Now you are ready to repeat the installation but with command line.


== Install Operator Using CLI

After you have installed the NFD operator and created an NFD resource with it you can learn 
in more details what exactly was installed and repeat this process from the command line.
That way you will be able to reproduce the process and automate it later.
Also, you will understand the overall Operators and OLM infrastructure much better.

. What operators are available?
+
[source,options="nowrap",subs="{markup-in-source}"]
----
$ *oc get packagemanifests -n openshift-marketplace*
NAME                                         CATALOG               AGE
percona-xtradb-cluster-operator              Community Operators   5h13m
robin-operator                               Certified Operators   5h13m
joget-dx-operator                            Certified Operators   5h13m
tigera-operator                              Certified Operators   5h13m
perceptilabs-operator-package-rhmp           Red Hat Marketplace   5h13m
cortex-certifai-operator-rhmp                Red Hat Marketplace   5h13m
appranix-cps-rhmp                            Red Hat Marketplace   5h13m
quay-bridge-operator                         Red Hat Operators     5h13m
portworx-essentials                          Community Operators   5h13m

. . . . SKIPPED . . . .

cic-operator                                 Certified Operators   5h13m
gpu-operator-certified                       Certified Operators   5h13m
ibm-management-ingress-operator-app          Certified Operators   5h13m
xcrypt-operator-rhmp                         Red Hat Marketplace   5h13m
joget-openshift-operator-rhmp                Red Hat Marketplace   5h13m
eddi-operator-certified-rhmp                 Red Hat Marketplace   5h13m
servicemeshoperator                          Red Hat Operators     5h13m
----
+
As you can see, there are four major categories of Operators in OpenShift:
+
* *Red Hat Operators*: Red Hat products packaged and shipped by Red Hat. Supported by Red Hat.
* *Red Hat Markeplace*: Red Hat and other products available in the Red Hat Marketplace.
* *Certified Operators*: Products from leading independent software vendors (ISVs). 
Red Hat partners with ISVs to package and ship. Supported by the ISV.
* *Community Operators*: Optionally-visible software maintained by relevant representatives 
in the operator-framework/community-operators GitHub repository. No official support.
+
Plus, there might be Custom Operators that you add to the cluster yourself. 

. We want to install the Node Feature Discovery Operator. 
Learn more about it from the Operator's description
+
[source,options="nowrap",subs="{markup-in-source}"]
----
$ *oc describe packagemanifests nfd -n openshift-marketplace*
Name:         nfd
Namespace:    openshift-marketplace
Labels:       catalog=redhat-operators
              catalog-namespace=openshift-marketplace
              olm-visibility=hidden
              openshift-marketplace=true
              operatorframework.io/arch.amd64=supported
              operatorframework.io/arch.ppc64le=supported
              operatorframework.io/arch.s390x=supported
              operatorframework.io/os.linux=supported
              opsrc-datastore=true
              opsrc-owner-name=redhat-operators
              opsrc-owner-namespace=openshift-marketplace
              opsrc-provider=redhat
              provider=Red Hat
              provider-url=
Annotations:  <none>
API Version:  packages.operators.coreos.com/v1
Kind:         PackageManifest
Metadata:
  Creation Timestamp:  2020-08-10T16:18:52Z
  Self Link:           /apis/packages.operators.coreos.com/v1/namespaces/openshift-marketplace/packagemanifests/nfd
Spec:
Status:
  Catalog Source:               redhat-operators
  Catalog Source Display Name:  Red Hat Operators
  Catalog Source Namespace:     openshift-marketplace
  Catalog Source Publisher:     Red Hat
  Channels:  
[...]  
  
  Default Channel:  4.5
  Package Name:     nfd
  Provider:
    Name:  Red Hat
Events:    <none>
----
+ 
There are several things we can learn from this output and use them to create a new subscription:
+
* The default channel: `4.5`
* The catalog source: `redhat-operators`
* The source namespace: `openshift-marketplace`
* The supported install modes: `OwnNamespace`, `SingleNamespace` and `AllNamespaces`. You will be using `AllNamespaces`

. Now follow the instructions in https://docs.openshift.com/container-platform/4.5/operators/olm-adding-operators-to-cluster.html#olm-installing-operator-from-operatorhub-using-cli_olm-adding-operators-to-a-cluster[documentation^] and create a YAML manifest using the information above:
+
[source,options="nowrap",subs="{markup-in-source}"]
----
apiVersion: operators.coreos.com/v1alpha1
kind: Subscription
metadata:
  name: nfd
  namespace: openshift-operators
spec:
  channel: "4.5"
  installPlanApproval: Automatic
  name: nfd
  source: redhat-operators
  sourceNamespace: openshift-marketplace
----
+
Save this manifest as a file named `nfd-sub.yaml` and create a new subscription:
+
[source,options="nowrap",subs="{markup-in-source}"]
----
$ *oc apply -f nfd-sub.yaml*
subscription.operators.coreos.com/nfd created
----

. Check if the Operator Pod is running:
+
[source,options="nowrap",subs="{markup-in-source}"]
----
$ *oc get pods -n openshift-operators*
NAME                            READY   STATUS    RESTARTS   AGE
nfd-operator-55dfcbbc7f-pg2gv   1/1     Running   0          3m34s
----

. The Operator is running but we have not created any NodeFeatureDiscovery resources that it is supposed to manage.
Take a look at the `oc describe` output above.
You can find an example of a resource you can create under `Alm - Examples`.
Create a file `nfd-resource.yaml` and copy the following there:
+
[source,options="nowrap",subs="{markup-in-source}"]
----
apiVersion: nfd.openshift.io/v1alpha1
kind: NodeFeatureDiscovery
metadata:
  name: nfd-master-server
  namespace: openshift-nfd
spec:
  namespace: openshift-nfd
----

. Create a new `NodeFeatureDiscovery` resource:
+
[source,options="nowrap",subs="{markup-in-source}"]
----
$ *oc apply -f nfd-resource.yaml*
nodefeaturediscovery.nfd.openshift.io/nfd-master-server created
----

. The `NodeFeatureDiscovery` resource called `nfd-master-server` is created in the `openshift-nfd` namespace and several OpenShift resources are deployed there. Let's check them.

. Run the following command to discover what was deployed in `openshift-nfd`:
+
[source,options="nowrap",subs="{markup-in-source}"]
----
$ *oc get all -n openshift-nfd*

NAME                   READY   STATUS    RESTARTS   AGE
pod/nfd-master-5jj7d   1/1     Running   0          21s
pod/nfd-master-q7blz   1/1     Running   0          21s
pod/nfd-master-vcsm6   1/1     Running   0          21s
pod/nfd-worker-dfjrz   1/1     Running   2          21s
pod/nfd-worker-dj8lc   1/1     Running   1          21s
pod/nfd-worker-rmzpk   1/1     Running   1          22s

NAME                 TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)     AGE
service/nfd-master   ClusterIP   172.30.77.186   <none>        12000/TCP   22s

NAME                        DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR                     AGE
daemonset.apps/nfd-master   3         3         3       3            3           node-role.kubernetes.io/master=   22s
daemonset.apps/nfd-worker   3         3         3       3            3           node-role.kubernetes.io/worker=   22s
----
+
Analyze the output. You can see that:
+
* Two DaemonSets were created: one on the master nodes and one on the worker nodes
* Pods are running on each node
* A Service was created
+
Those Pods collect hardware and OS-related information from the nodes and use it to add
labels to them.

. Check the labels added by `NodeFeatureDiscovery` to one of the nodes:
+
[source,options="nowrap",subs="{markup-in-source}"]
----
$ *oc get nodes*

NAME                          STATUS   ROLES                AGE     VERSION
cluster-7a2f-bl5bg-master-0   Ready    master               5h24m   v1.18.3+08c38ef
cluster-7a2f-bl5bg-master-1   Ready    master               5h24m   v1.18.3+08c38ef
cluster-7a2f-bl5bg-master-2   Ready    master               5h24m   v1.18.3+08c38ef
general-purpose-1a-dcfvh      Ready    general-use,worker   132m    v1.18.3+08c38ef
general-purpose-1b-jgjkd      Ready    general-use,worker   131m    v1.18.3+08c38ef
infra-1a-s2hqz                Ready    infra,worker         134m    v1.18.3+08c38ef

$ oc get node general-purpose-1a-dcfvh -o json | jq '.metadata.labels'

{
  "beta.kubernetes.io/arch": "amd64",
  "beta.kubernetes.io/instance-type": "4c12g30d",
  "beta.kubernetes.io/os": "linux",
  "failure-domain.beta.kubernetes.io/region": "regionOne",
  "failure-domain.beta.kubernetes.io/zone": "nova",
  "feature.node.kubernetes.io/cpu-cpuid.ADX": "true",
  "feature.node.kubernetes.io/cpu-cpuid.AESNI": "true",
  "feature.node.kubernetes.io/cpu-cpuid.AVX": "true",
  "feature.node.kubernetes.io/cpu-cpuid.AVX2": "true",
  "feature.node.kubernetes.io/cpu-cpuid.FMA3": "true",
  "feature.node.kubernetes.io/cpu-cpuid.HLE": "true",
  "feature.node.kubernetes.io/cpu-cpuid.IBPB": "true",
  "feature.node.kubernetes.io/cpu-cpuid.RTM": "true",
  "feature.node.kubernetes.io/cpu-cpuid.STIBP": "true",
  "feature.node.kubernetes.io/kernel-selinux.enabled": "true",
  "feature.node.kubernetes.io/kernel-version.full": "4.18.0-193.14.3.el8_2.x86_64",
  "feature.node.kubernetes.io/kernel-version.major": "4",
  "feature.node.kubernetes.io/kernel-version.minor": "18",
  "feature.node.kubernetes.io/kernel-version.revision": "0",
  "feature.node.kubernetes.io/pci-1013.present": "true",
  "feature.node.kubernetes.io/pci-1af4.present": "true",
  "feature.node.kubernetes.io/system-os_release.ID": "rhcos",
  "feature.node.kubernetes.io/system-os_release.VERSION_ID": "4.5",
  "feature.node.kubernetes.io/system-os_release.VERSION_ID.major": "4",
  "feature.node.kubernetes.io/system-os_release.VERSION_ID.minor": "5",
  "kubernetes.io/arch": "amd64",
  "kubernetes.io/hostname": "general-purpose-1a-dcfvh",
  "kubernetes.io/os": "linux",
  "node-role.kubernetes.io/general-use": "",
  "node-role.kubernetes.io/worker": "",
  "node.kubernetes.io/instance-type": "4c12g30d",
  "node.openshift.io/os_id": "rhcos",
  "topology.kubernetes.io/region": "regionOne",
  "topology.kubernetes.io/zone": "nova"
}
----
+
As you can see you can find out if certain hardware features are supported on your nodes.
For example, various CPUID codes are described here: https://en.wikipedia.org/wiki/CPUID


=== Explore ClusterServiceVersions

When an Operator is installed in the cluster, it keeps the information about itself in a resource called ClusterServiceVersion, or `csv`.
In this exercise you explore it and find various pieces of information you can retrieve and use.

. Start with finding the CSV's name for the NodeFeatureDiscovery operator you've just installed.
+
[source,options="nowrap",subs="{markup-in-source}"]
----
$ *oc get csv -n openshift-operators*

NAME                        DISPLAY                  VERSION   REPLACES   PHASE
nfd.4.5.0-202007281827.p0   Node Feature Discovery   4.5.0                Succeeded
----
+
Look into other namespaces:
+
[source,options="nowrap",subs="{markup-in-source}"]
----
$ oc get csv -A
NAMESPACE                                          NAME                        DISPLAY                  VERSION   REPLACES   PHASE
default                                            nfd.4.5.0-202007281827.p0   Node Feature Discovery   4.5.0                Succeeded
kube-node-lease                                    nfd.4.5.0-202007281827.p0   Node Feature Discovery   4.5.0                Succeeded
kube-public                                        nfd.4.5.0-202007281827.p0   Node Feature Discovery   4.5.0                Succeeded
kube-system                                        nfd.4.5.0-202007281827.p0   Node Feature Discovery   4.5.0                Succeeded
node-ssh                                           nfd.4.5.0-202007281827.p0   Node Feature Discovery   4.5.0                Succeeded
openshift-apiserver-operator                       nfd.4.5.0-202007281827.p0   Node Feature Discovery   4.5.0                Succeeded
openshift-apiserver                                nfd.4.5.0-202007281827.p0   Node Feature Discovery   4.5.0                Succeeded
openshift-authentication-operator                  nfd.4.5.0-202007281827.p0   Node Feature Discovery   4.5.0                Succeeded
openshift-authentication                           nfd.4.5.0-202007281827.p0   Node Feature Discovery   4.5.0                Succeeded

. . . . SKIPPED . . . .
----
+
As you can see the Operator was copied into all existing namespaces -- exactly what 
we discovered when installing it via web console.

. Look into the CSV's YAML manifest:
+
[source,options="nowrap",subs="{markup-in-source}"]
----
$ *oc get csv nfd.4.5.0-202007281827.p0 -n openshift-operators -o yaml*

. . . . SKIPPED . . . .
----
+
That's a lot of information. Let's find the most important parts.
+
* The Custom Resource example: a JSON file which you can use to create an instance of NodeFeatureDiscovery
* The `spec.customresourcedefinitions` which can include the `owned` and `required` parts.
They define the resources managed by this Operator and also its dependencies.
This Operator has only the `owned` part. Some Operators also have dependencies 
(you will see them later when installing the Service Mesh Operator).
* The `spec.icon` data: it's a logo you see in the web console.
* The `spec.install` part: here you can see the Operator's installtion instructions and
parameters.
* The `spec.installModes` list: what install modes are supported (AllNamespaces, OwnNamespace, etc.)
* The Github URLs where you can find source code and additional documentation for the Operator
and its resources.

. Sometimes you have to use certain Operator's parameters in scripts.
Practice with the following one-liners to extract some useful fields from the CSV.
+
Get the name:
+
[source,options="nowrap"]
----
$ oc get csv nfd.4.5.0-202007281827.p0 -n openshift-operators -o json | jq '.metadata.name'
----
+
Get the version:
+
[source,options="nowrap"]
----
$ oc get csv nfd.4.5.0-202007281827.p0 -n openshift-operators -o json | jq '.spec.version'
----
+
Get the list of CRDs owned by this CSV:
+
[source,options="nowrap"]
----
$ oc get csv nfd.4.5.0-202007281827.p0 -n openshift-operators -o json | jq '.spec.customresourcedefinitions.owned[].kind'
----

Read more about CSV and its metadata here: https://github.com/operator-framework/operator-lifecycle-manager/blob/master/doc/design/building-your-csv.md


== Disable and Enable Operator Sources

Sometimes cluster administrators want to limit access to some operator sources.
For example, they want to install only the Operators produced by Red Hat or certified by Red Hat.
That means they might want to disable the Community Operators catalog.

In this exercise you will disable that catalog, make sure that operators from it are not visible in the cluster.
After that you will enable the catalog again to be able to use it in the future labs.

. OperatorSource is a custom resource in OpenShift. 
You can find them in the `openshift-marketplace` namespace.
+
[source,options="nowrap",subs="{markup-in-source}"]
----
$ *oc get operatorsource -n openshift-marketplace*

NAME                  TYPE          ENDPOINT              REGISTRY              DISPLAYNAME           PUBLISHER   STATUS      MESSAGE                                       AGE
certified-operators   appregistry   https://quay.io/cnr   certified-operators   Certified Operators   Red Hat     Succeeded   The object has been successfully reconciled   5h23m
community-operators   appregistry   https://quay.io/cnr   community-operators   Community Operators   Red Hat     Succeeded   The object has been successfully reconciled   5h23m
redhat-marketplace    appregistry   https://quay.io/cnr   redhat-marketplace    Red Hat Marketplace   Red Hat     Succeeded   The object has been successfully reconciled   5h23m
redhat-operators      appregistry   https://quay.io/cnr   redhat-operators      Red Hat Operators     Red Hat     Succeeded   The object has been successfully reconciled   5h23m
----

. Take a look at the `certified-operators` OperatorSource:
+
[source,options="nowrap",subs="{markup-in-source}"]
----
$ *oc get operatorsource certified-operators -n openshift-marketplace -o yaml*

apiVersion: operators.coreos.com/v1
kind: OperatorSource
metadata:
  creationTimestamp: "2020-08-10T16:18:51Z"
  finalizers:
  - finalizer.operatorsources.operators.coreos.com
  generation: 9
  labels:
    opsrc-provider: certified
  managedFields:

[...]

  name: certified-operators
  namespace: openshift-marketplace
  resourceVersion: "100240"
  selfLink: /apis/operators.coreos.com/v1/namespaces/openshift-marketplace/operatorsources/certified-operators
  uid: 5181e372-7769-4393-b889-5fbe3a142853
spec:
  authorizationToken: {}
  displayName: Certified Operators
  endpoint: https://quay.io/cnr
  publisher: Red Hat
  registryNamespace: certified-operators
  type: appregistry
status:
  currentPhase:
    lastTransitionTime: "2020-08-10T19:51:38Z"
    lastUpdateTime: "2020-08-10T19:51:38Z"
    phase:
      message: The object has been successfully reconciled
      name: Succeeded
  packages: hazelcast-enterprise-certified,percona-server-mongodb-operator-certified,joget-openshift-operator,seldon-operator-certified,cert-manager-operator,instana-agent,cyberarmor-operator-certified,cortex-hub-operator,fp-predict-plus-operator-certified,perceptilabs-operator-package,ibm-helm-api-operator-app,nxrm-operator-certified,percona-xtradb-cluster-operator-certified,storageos-10tb,f5-bigip-ctlr-operator,kubeturbo-marketplace-certified,cortex-healthcare-hub-operator,cass-operator,cnvrg-operator,sematext,ubix-operator,ibm-management-ingress-operator-app,tigera-operator,ibm-monitoring-grafana-operator-app,redhat-marketplace-operator,anzograph-operator,anchore-engine,presto-operator,nuodb-ce-certified,portshift-operator,ibm-platform-api-operator-app,vprotect-operator,falco-certified,orca,t8c-certified,eddi-operator-certified,neuvector-certified-operator,here-service-operator-certified,zabbix-operator-certified,ibm-spectrum-scale-csi,rapidbiz-operator-certified,hspc-operator,portworx-certified,cpx-cic-operator,k8s-triliovault,sysdig-certified,triggermesh-operator,aqua-certified,citrix-cpx-istio-sidecar-injector-operator,traefikee-redhat-certified,ibm-licensing-operator-app,tidb-operator-certified,ibm-block-csi-operator,aqua-operator-certified,cortex-certifai-operator,cih-operator-certified,cortex-fabric-operator,ocean-operator,datadog-operator-certified,hpe-csi-operator,node-red-operator-certified,tf-operator,akka-cluster-operator-certified,ivory-server-app,storageos-1tb,infinibox-operator-certified,nxiq-operator-certified,uma-operator,appranix-cps,mongodb-enterprise,oneagent-certified,appdynamics-operator,openunison-ocp-certified,cic-operator,kube-arangodb,insightedge-enterprise-operator2,traefikee-certified,gitlab-operator,kong-offline-operator,robin-operator,open-liberty-certified,kubemq-operator,couchbase-enterprise-certified,synopsys-certified,ibm-spectrum-symphony-operator,openshiftxray-operator,linstor-operator,appsody-operator-certified,redis-enterprise-operator-cert,joget-dx-operator,openshiftartifactoryha-operator,yugabyte-operator,rocketchat-operator-certified,vfunction-server-operator,newrelic-infrastructure,cockroachdb-certified,open-enterprise-spinnaker,cortex-operator,couchdb-operator-certified,splunk-certified,transadv-operator,planetscale-certified,crunchy-postgres-operator,kubeturbo-certified,nginx-ingress-operator,ibm-mongodb-operator-app,aci-containers-operator,wavefront-operator,timemachine-operator,kubemq-operator-marketplace,gpu-operator-certified,cic-operator-with-crds,federatorai-certified,driverlessai-deployment-operator-certified,ibm-helm-repo-operator-app,alcide-kaudit-operator,anaconda-team-edition,universalagent-operator-certified,citrix-adc-istio-ingress-gateway-operator,dotscience-operator,xcrypt-operator,storageos,memql-certified,twistlock-certified,runtime-component-operator-certified,transform-adv-operator,aws-event-sources-operator,kong,ibm-auditlogging-operator-app,atomicorp-helm-operator-certified,hazelcast-jet-enterprise-operator
----
+
You can find the following information here:
+
* The name of the resource and the namespace where it's located (by default it's `openshift-marketplace`)
* The publisher's name (Red Hat in this case)
* The list of packages available from this OperatorSource

. The list of OperatorSources is maintained by the OperatorHub cluster resource.
Find it (no need to specify the namespace as it's a cluster-wide resource):
+
[source,options="nowrap",subs="{markup-in-source}"]
----
$ *oc get operatorhubs*
NAME      AGE
cluster   24h
----
+
Look inside:
+
[source,options="nowrap",subs="{markup-in-source}"]
----
$ *oc get operatorhubs cluster -o yaml*

apiVersion: config.openshift.io/v1
kind: OperatorHub
metadata:
  annotations:
    release.openshift.io/create-only: "true"
  creationTimestamp: "2020-08-10T16:14:05Z"
  generation: 1
  managedFields:

[...]  
  
  name: cluster
  resourceVersion: "99997"
  selfLink: /apis/config.openshift.io/v1/operatorhubs/cluster
  uid: 48c8988c-4421-49d7-b460-c043b5e3a8e6
spec: {}
status:
  sources:
  - disabled: false
    name: redhat-operators
    status: Success
  - disabled: false
    name: certified-operators
    status: Success
  - disabled: false
    name: community-operators
    status: Success
  - disabled: false
    name: redhat-marketplace
    status: Success
----
+
As you can see, the `spec` part is empty. That means the OperatorHub will use the defaults.
By default all OperatorSources are enabled as you can see in the `status` part.

. To disable an OperatorSource we have to fill the `spec` part with the information from the `status` part and then disable one of the sources.
You can edit the `operatorhub` resource either by using the `oc edit` command or by using the embedded OpenShift YAML editor (available since version 4.2).
+
To use the latter way go to *Administration* -> *Cluster Settings* -> 
*Global Configuration* -> *OperatorHub*. Then open the *YAML* tab.
+
To use the command line way simply type `oc edit operatorhub cluster`.
+
You should remove the `{}` in the `spec` part and copy the list or sources from the `status` part.
After that remove the `status: Success` lines.
Finally change `false` to `true` in the `disabled:` line for `community-operators`.
You `spec` part should look like this:
+
[source,yaml,options="nowrap",subs="{markup-in-source}"]
----
. . .
spec:
  sources:
  - disabled: false
    name: redhat-operators
  - disabled: false
    name: certified-operators
  *- disabled: true*
    name: community-operators
. . .
----
+
Save the YAML manifest (depending on the method you used for editing).

. Now test if you can see the disabled source:
+
[source,options="nowrap",subs="{markup-in-source}"]
----
$ *oc get operatorsource -n openshift-marketplace*
NAME                  TYPE          ENDPOINT              REGISTRY              DISPLAYNAME           PUBLISHER   STATUS      MESSAGE                                       AGE
certified-operators   appregistry   https://quay.io/cnr   certified-operators   Certified Operators   Red Hat     Succeeded   The object has been successfully reconciled   5h27m
redhat-marketplace    appregistry   https://quay.io/cnr   redhat-marketplace    Red Hat Marketplace   Red Hat     Succeeded   The object has been successfully reconciled   5h27m
redhat-operators      appregistry   https://quay.io/cnr   redhat-operators      Red Hat Operators     Red Hat     Succeeded   The object has been successfully reconciled   5h27m
----
+
Only three OperatorSources are available.

. Check it from the GUI console. Go to *Operators* -> *OperatorHub* and choose *All Items*.
You should see only three items in the *Provider Type* section: *Red Hat*, *Marketplace* and *Certified*. The Community type disappeared.

. Now enable the OperatorSource again using exactly the same way - by editing the `operatorhub` YAML manifest.
Make sure the community operators are available before moving to the next lab. 

== Summary

Now you know how to install and uninstall operators from the OperatorHub, both via web console and command line. You know the most important components of an Operator and you know how to analyze operators. Practice installing other operators from the OperatorHub and learn about their components and services.

This concludes this lab.
